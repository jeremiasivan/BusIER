---
title: "Data Download from NCBI"
output:
  html_document:
    code_folding: show

params:
  # general
  codedir: "~/BusIER/codes"
  prefix: ""
  outdir: "~/busco"
  thread: 5
  redo: TRUE
  
  # list of accession numbers to be downloaded
  file_refseq: ""
  file_shortreads: ""

  exe_datasets: ""
  bin_sratoolkit: ""
---

## Load required libraries and functions
```{r}
source(paste0(params$codedir, "/1_data_download/functions.R"))

library(doSNOW)
```

```{r, include=FALSE}
# install.packages("data.table")
# install.packages("log4r")

# store initial system time
sys_tic <- Sys.time()

# create outdir
currentdir <- paste0(params$outdir, "/", params$prefix)
if (!dir.exists(currentdir)) {
  dir.create(currentdir, recursive = T)
}

# create directory for log files
logdir <- paste0(currentdir, "/logs/")
if (!dir.exists(logdir)) {
  dir.create(logdir, recursive = T)
}

# create log file
fn_log <- paste0(logdir, params$prefix, ".download.log")
log_appender <- log4r::file_appender(fn_log, append = TRUE, layout = log4r::default_log_layout())
fn_logger <- log4r::logger(threshold = "INFO", appenders = log_appender)
if (!file.exists(fn_log) || params$redo) {
  unlink(fn_log)
  f_write_log(fn_log=fn_log, msg="BusIER")
}

knitr::opts_knit$set(root.dir = currentdir)
```

```{r, include=FALSE}
f_write_log(fn_log=fn_log,
            msg=c("", "####################################",
                      "####        Data Download       ####",
                      "####################################"))

# create refseq directory
dir_refseq <- paste0(currentdir, "/refseq/")
if (!dir.exists(dir_refseq)) {
  dir.create(dir_refseq, recursive = T)
}

# create shortreads directory
dir_shortreads <- paste0(currentdir, "/short_reads/")
if (!dir.exists(dir_shortreads)) {
  dir.create(dir_shortreads, recursive = T)
}
```

## Download reference genome FASTA alignments from NCBI
```{r, include=FALSE}
f_write_log(fn_log=fn_log,
            msg=c("", "------------ Reference Sequences -----------"))

# initiate variable to store list of reference sequences
ls_refseq <- NULL
is_refseq_available <- FALSE

ls_refseq_available <- NULL
ls_refseq_download <- NULL

# open the file that contains the list of reference sequences
if (params$file_refseq != "" && !is.null(params$file_refseq)) {
  ls_refseq <- data.table::fread(params$file_refseq, select="id")
  ls_refseq <- ls_refseq$id
}

# check the length of the reference sequences
if (length(ls_refseq) == 0 || is.null(ls_refseq)) {
  f_write_log(fn_log=fn_log, msg="Warn: list of reference sequence has length zero")
} else {
  f_write_log(fn_log=fn_log, msg=paste("Number of reference sequences:", length(ls_refseq)))

  # update the list of reference sequences to be downloaded
  if (params$redo) {
    ls_refseq_download <- ls_refseq
  } else {
    for (ref in ls_refseq) {
      dir_output_fna <- paste0(dir_refseq, "/", ref, "/ncbi_dataset/data/", ref, "/")

      # check if file exists
      if (length(list.files(dir_output_fna, pattern="*.fna$", recursive=F)) > 0) {
        ls_refseq_available <- c(ls_refseq_available, paste("-", ref))
      } else {
        ls_refseq_download <- c(ls_refseq_download, ref)
      }
    }
  }
  
  # output log file for available reference sequences
  if (length(ls_refseq_available) > 0) {
    ls_refseq_available <- c(paste0("Available reference sequences (", length(ls_refseq_available), "/", length(ls_refseq), ")"), ls_refseq_available, "")
    f_write_log(fn_log=fn_log, msg=ls_refseq_available)
  }

  # update variable for the next analysis
  if (length(ls_refseq_download) > 0) {
    is_refseq_available <- TRUE
  }
}
```

```{r download-refseq, include=is_refseq_available, eval=is_refseq_available}
# update number of thread
nthread <- params$thread
if (nthread > length(ls_refseq_download)) {
  nthread <- length(ls_refseq_download)
}

# create doSNOW cluster
nwcl <- makeCluster(nthread)
doSNOW::registerDoSNOW(nwcl)

# iterate through reference sequences
foreach (ref = ls_refseq_download) %dopar% {
    # output file
    file_output_zip <- paste0(dir_refseq, ref, ".zip")
    
    # delete the zip file
    unlink(file_output_zip)

    # download the reference sequence
    f_refseq_download(params$exe_datasets, ref, file_output_zip)

    # check if folder exists
    dir_output <- paste0(dir_refseq, ref, "/")
    if (!dir.exists(dir_output) || params$redo) {
        dir.create(dir_output, recursive=T)
        unzip(file_output_zip, exdir=dir_output, overwrite=TRUE)
    }

    # delete the zip file
    unlink(file_output_zip)

    log4r::info(fn_logger, paste0("File downloaded: genome alignment for ", ref, "."))
}

stopCluster(nwcl)
```
## Download short reads FASTQ alignments from NCBI
```{r, include=FALSE}
f_write_log(fn_log=fn_log,
            msg=c("", "---------------- Short Reads ---------------"))

# initiate variable to store list of reference sequences
ls_shortreads <- NULL
is_shortreads_available <- FALSE

ls_reads_available <- NULL
ls_reads_download <- NULL

# open the file that contains the list of short reads
if (params$file_shortreads != "" && !is.null(params$file_shortreads)) {
  ls_shortreads <- data.table::fread(params$file_shortreads, select="id")
  ls_shortreads <- ls_shortreads$id
}

# check the length of the short reads
if (length(ls_shortreads) == 0 || is.null(ls_shortreads)) {
  f_write_log(fn_log=fn_log, msg="Warn: list of short reads has length zero")
} else {
  f_write_log(fn_log=fn_log, msg=paste("Number of short reads:", length(ls_shortreads)))

  # update the list of short reads to be downloaded
  if (params$redo) {
    ls_reads_download <- ls_shortreads
  } else {
    for (read in ls_shortreads) {
      dir_output_fastq <- paste0(dir_shortreads, read, "/fastq/")

      # check if file exists
      if (length(list.files(dir_output_fastq, pattern="*.fastq$", recursive=F)) > 0) {
        ls_reads_available <- c(ls_reads_available, paste("-", read))
      } else {
        ls_reads_download <- c(ls_reads_download, read)
      }
    }
  }

  # output log file for available short reads
  if (length(ls_reads_available) > 0) {
    ls_reads_available <- c(paste0("Available short reads (", length(ls_reads_available), "/", length(ls_shortreads), ")"), ls_reads_available, "")
    f_write_log(fn_log=fn_log, msg=ls_reads_available)
  }

  # update variable for the next analysis
  if (length(ls_reads_download) > 0) {
    is_shortreads_available <- TRUE
  }
}
```

```{r download-shortreads, include=is_shortreads_available, eval=is_shortreads_available}
# update number of thread
nthread <- params$thread
if (nthread > length(ls_reads_download)) {
  nthread <- length(ls_reads_download)
}

# create doSNOW cluster
nwcl <- makeCluster(nthread)
doSNOW::registerDoSNOW(nwcl)

# iterate through short reads
foreach (read = ls_reads_download) %dopar% {
    # download the short reads
    f_shortreads_download(params$bin_sratoolkit, read, dir_shortreads)
    log4r::info(fn_logger, paste0("File downloaded: FASTQ alignment for ", read, "."))
}

stopCluster(nwcl)
```

```{r, include=FALSE}
# store final system time
sys_toc <- Sys.time()

# write the system time in log file
f_write_log(fn_log=fn_log, msg=c("", paste0("Total elapsed time: ", round(as.numeric(difftime(sys_toc, sys_tic, units = "mins")), 3), " mins")))
```